{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5444949e",
   "metadata": {},
   "source": [
    "# Basketabll Activity Recognition using LSTM Neural Network\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcd6264",
   "metadata": {},
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9208b1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-14 20:31:38.961504: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-14 20:31:38.961528: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/shk/anaconda3/envs/adversarial/lib/python3.7/site-packages/ipykernel_launcher.py:33: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_data (613454, 6)\n",
      "____\n",
      "game_data (45111, 6)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, jaccard_score,confusion_matrix, plot_confusion_matrix\n",
    "import time\n",
    "from typing import Any\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, LSTM\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, RepeatedKFold\n",
    "from sklearn.metrics import f1_score, confusion_matrix, plot_confusion_matrix\n",
    "from pandas import DataFrame\n",
    "from keras.models import load_model\n",
    "\n",
    "files = glob.glob('/data/shk/dl-for-har/tutorial_notebooks/Prof_New/*.csv')\n",
    "\n",
    "name = [file.split('/')[-1] for file in files]\n",
    "df = pd.concat(map(pd.read_csv,files),ignore_index = True) #4230213 rows × 10 columns\n",
    "\n",
    "data = df\n",
    "\n",
    "#Considering only basketball\n",
    "clean_data = data[data['basketball']!='not_labeled']\n",
    "clean_data = clean_data[data['basketball'].notna()]\n",
    "clean_data['basketball'].replace({'jumping':'layup'},inplace=True) #Replacing jumping by layup\n",
    "\n",
    "new_data = clean_data[clean_data.coarse != 'game'] #623758 rows × 10 columns\n",
    "new_data = new_data.drop(columns='coarse')\n",
    "new_data = new_data.iloc[:,:6]\n",
    "print('new_data',new_data.shape)\n",
    "print('____')\n",
    "\n",
    "# Sepearting Game data from train data\n",
    "game_data = clean_data[clean_data.coarse == 'game']\n",
    "game_data = game_data.drop(columns='coarse')\n",
    "game_data = game_data.iloc[:,:6] #45446 rows × 6 columns\n",
    "print('game_data',game_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d244180c",
   "metadata": {},
   "source": [
    "# Labelling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88a196df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shk/anaconda3/envs/adversarial/lib/python3.7/site-packages/ipykernel_launcher.py:25: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n"
     ]
    }
   ],
   "source": [
    "label = new_data['basketball']\n",
    "x_axis = sorted(label.unique())\n",
    "y_axis = label.value_counts()\n",
    "\n",
    "X = new_data.iloc[:,:-1]#.astype(np.float32)\n",
    "\n",
    "class_names = ['dribbling','shot','pass','layup','rebound']\n",
    "num_classes = len(class_names)\n",
    "\n",
    "def labelling(clean_data,data_y):\n",
    "    clean_data[data_y == 'dribbling'] = 0\n",
    "    clean_data[data_y == 'shot'] = 1\n",
    "    clean_data[data_y == 'pass'] = 2\n",
    "    clean_data[data_y == 'layup'] = 3\n",
    "    clean_data[data_y == 'rebound'] = 4\n",
    "    \n",
    "    return data_y\n",
    "\n",
    "y = labelling(new_data,new_data.iloc[:,-1]).astype(int)\n",
    "\n",
    "#subject = X['subject']\n",
    "#uni_subject = subject.unique()\n",
    "#uni_subject_count = subject.value_counts()\n",
    "\n",
    "data_labelled = np.concatenate((X, y[:,None]), axis=1)[:,1:] #669204, 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724753e3",
   "metadata": {},
   "source": [
    "# Special preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3589f71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bribbling = data_labelled[data_labelled[:,-1] == 0]\n",
    "data_shot = data_labelled[data_labelled[:,-1] == 1]\n",
    "data_pass = data_labelled[data_labelled[:,-1] == 2]\n",
    "data_layup = data_labelled[data_labelled[:,-1] == 3]\n",
    "data_rebound = data_labelled[data_labelled[:,-1] == 4]\n",
    "\n",
    "\n",
    "def spilt(data):\n",
    "\n",
    "    dd = np.asarray(data)\n",
    "    T = int(0.8* len(dd))\n",
    "    train_size = int(T)\n",
    "    test_size = len(dd) - train_size\n",
    "\n",
    "    train_df,test_df = torch.utils.data.random_split(dd, [train_size,test_size])\n",
    "    X = train_df[:][:,0:4]\n",
    "    Y = train_df[:][:,4]\n",
    "\n",
    "    X_v = test_df[:][:,0:4]\n",
    "    y_v = test_df[:][:,4]\n",
    "  \n",
    "    return X,Y,X_v,y_v\n",
    "\n",
    "X_dribble,Y_dribble,X_v_dribble,y_v_dribble = spilt(data_bribbling)\n",
    "X_shot,Y_shot,X_v_shot,y_v_shot = spilt(data_shot)\n",
    "X_pass,Y_pass,X_v_pass,y_v_pass = spilt(data_pass)\n",
    "X_layup,Y_layup,X_v_layup,y_v_layup = spilt(data_layup)\n",
    "X_rebound,Y_rebound,X_v_rebound,y_v_rebound = spilt(data_rebound)\n",
    "\n",
    "X = np.concatenate((X_dribble, X_shot,X_pass,X_layup,X_rebound), axis=0)[:,1:]\n",
    "Y = np.concatenate((Y_dribble, Y_shot,Y_pass,Y_layup,Y_rebound), axis=0)\n",
    "\n",
    "X_v = np.concatenate((X_v_dribble, X_v_shot,X_v_pass,X_v_layup,X_v_rebound), axis=0)[:,1:]\n",
    "y_v = np.concatenate((y_v_dribble, y_v_shot,y_v_pass,y_v_layup,y_v_rebound), axis=0)\n",
    "\n",
    "train_data = np.column_stack((X,Y))\n",
    "valid_data = np.column_stack((X_v,y_v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75eed997",
   "metadata": {},
   "source": [
    "# Sliding Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "946dc29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of the X_train and Y_train datasets after windowing: \n",
      "(12914, 50, 3) (12914, 50)\n",
      "\n",
      "Shape of the X_valid and y_valid datasets after windowing: \n",
      "(3228, 50, 3) (3228, 50)\n",
      "\n",
      "Shape of the X after windowing: \n",
      "(16142, 50, 3)\n",
      "\n",
      "Shape of the Y after windowing: \n",
      "(16142,)\n"
     ]
    }
   ],
   "source": [
    "def sliding_window(data, samples_per_window, overlap_ratio):\n",
    "    windows = []\n",
    "    indices = []\n",
    "    curr = 0\n",
    "    win_len = int(samples_per_window)\n",
    "    \n",
    "    if overlap_ratio is not None:\n",
    "        overlapping_elements = int((overlap_ratio / 100) * (win_len))\n",
    "        if overlapping_elements >= win_len:\n",
    "            print('Number of overlapping elements exceeds window size.')\n",
    "            return\n",
    "    while curr < len(data) - win_len:\n",
    "        windows.append(data[curr:curr + win_len])\n",
    "        indices.append([curr, curr + win_len])\n",
    "        curr = curr + win_len - overlapping_elements\n",
    "    try:\n",
    "        result_windows = np.array(windows)\n",
    "        result_indices = np.array(indices)\n",
    "    except:\n",
    "        result_windows = np.empty(shape=(len(windows), win_len, data.shape[1]), dtype=object)\n",
    "        result_indices = np.array(indices)\n",
    "        for i in range(0, len(windows)):\n",
    "            result_windows[i] = windows[i]\n",
    "            result_indices[i] = indices[i]\n",
    "    return result_windows, result_indices\n",
    "\n",
    "def apply_sliding_window(data_x, data_y, sliding_window_size, sampling_rate, sliding_window_overlap):\n",
    "    \n",
    "    output_x, _ = sliding_window(data_x, sliding_window_size, sliding_window_overlap)\n",
    "    output_y, _ = sliding_window(data_y, sliding_window_size, sliding_window_overlap)\n",
    "\n",
    "    return output_x,output_y\n",
    "\n",
    "sw_length = 50\n",
    "sw_overlap = 25\n",
    "\n",
    "X_train, y_train = apply_sliding_window(X, Y, sw_length, sampling_rate=50,sliding_window_overlap=sw_overlap)\n",
    "X_valid, y_valid = apply_sliding_window(X_v, y_v, sw_length, sampling_rate=50,sliding_window_overlap=sw_overlap)\n",
    "\n",
    "\n",
    "X_train, y_train = X_train.astype(np.float32), y_train.astype(np.uint8)\n",
    "X_valid, y_valid = X_valid.astype(np.float32), y_valid.astype(np.uint8)\n",
    "\n",
    "print(\"\\nShape of the X_train and Y_train datasets after windowing: \")\n",
    "print(X_train.shape, y_train.shape) \n",
    "\n",
    "print(\"\\nShape of the X_valid and y_valid datasets after windowing: \")\n",
    "print(X_valid.shape, y_valid.shape)\n",
    "\n",
    "y_train = y_train[:,0]\n",
    "y_valid = y_valid[:,0]\n",
    "\n",
    "data_X = np.concatenate((X_train,X_valid),axis=0) \n",
    "\n",
    "print(\"\\nShape of the X after windowing: \")\n",
    "print(data_X.shape)\n",
    "\n",
    "print(\"\\nShape of the Y after windowing: \")\n",
    "data_Y = np.concatenate((y_train,y_valid),axis=0) \n",
    "print(data_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920efc43",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff78886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Network(X_train,y_train,X_valid, y_valid):\n",
    "\n",
    "    train_preds = []\n",
    "    train_gt = []\n",
    "    test_preds = []\n",
    "    test_gt = []   \n",
    "    loss_acc = []\n",
    "    c_matrix =[]\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=26,input_shape=[X_train.shape[1], X_train.shape[2]], activation = 'relu', return_sequences = True))\n",
    "    model.add(Dropout(rate=0.1))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=1300, activation='relu'))\n",
    "    model.add(Dropout(rate=0.2))\n",
    "\n",
    "    model.add(Dense(units=850, activation='relu'))\n",
    "    model.add(Dropout(rate=0.3))\n",
    "    model.add(Dense(units=5, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train,y_train,epochs=20, validation_data=(X_valid,y_valid),verbose=1)\n",
    "\n",
    "    y_pred_train = np.argmax(model.predict(X_train), axis=-1)\n",
    "    y_pred_test = np.argmax(model.predict(X_valid), axis=-1)\n",
    "        \n",
    "        \n",
    "    #Training\n",
    "    acc_train = jaccard_score(y_train, y_pred_train, average='macro')\n",
    "    pre_train = precision_score(y_train, y_pred_train, average='macro', zero_division=0)\n",
    "    reca_train = recall_score(y_train, y_pred_train, average='macro', zero_division=0)\n",
    "    f1_train = f1_score(y_train, y_pred_train, average='macro', zero_division=0)\n",
    "\n",
    "    train_preds = np.concatenate((np.array(train_preds, int), np.array(y_pred_train, int)))\n",
    "    train_gt = np.concatenate((np.array(train_gt, int), np.array(y_train, int)))\n",
    "\n",
    "    print(\"___Training____\")\n",
    "    print(f\"accuracy {round(acc_train,3)*100} ,precision {round(pre_train,3)*100}, recall {round(reca_train,3)*100},f1_score {round(f1_train,3)*100} \")\n",
    "\n",
    "        #Validation\n",
    "    acc_test = jaccard_score(y_valid, y_pred_test, average='macro')\n",
    "    pre_test = precision_score(y_valid, y_pred_test, average='macro', zero_division=0)\n",
    "    reca_test = recall_score(y_valid, y_pred_test, average='macro', zero_division=0)\n",
    "    f1_test = f1_score(y_valid, y_pred_test, average='macro', zero_division=0)\n",
    "\n",
    "    test_preds = np.concatenate((np.array(test_preds, int), np.array(y_pred_test, int)))\n",
    "    test_gt = np.concatenate((np.array(test_gt, int), np.array(y_valid, int)))\n",
    "\n",
    "    print(\"___Validation____\")\n",
    "    print(f\"accuracy {round(acc_test,3)*100} ,precision {round(pre_test,3)*100}, recall {round(reca_test,3)*100}, f1_score {round(f1_test,3)*100} \")\n",
    "\n",
    "        #Genarate Metrics\n",
    "    loss_acc.append(model.evaluate(X_valid,y_valid))\n",
    "    c_matrix.append(confusion_matrix(y_valid, y_pred_test))   \n",
    "\n",
    "        #Save Weights\n",
    "    model.save_weights('./Pre_Trained_models/without_k_fold/without_k_fold',overwrite=True)\n",
    "    model.save('./Pre_Trained_models/without_k_fold',overwrite=True)\n",
    "    \n",
    "    return train_preds,train_gt,test_preds,test_gt,loss_acc,matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c641e817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-14 20:31:46.451809: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_COMPAT_NOT_SUPPORTED_ON_DEVICE: forward compatibility was attempted on non supported HW\n",
      "2022-08-14 20:31:46.451832: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: DeepCube\n",
      "2022-08-14 20:31:46.451837: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: DeepCube\n",
      "2022-08-14 20:31:46.451898: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2022-08-14 20:31:46.451919: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 470.129.6\n",
      "2022-08-14 20:31:46.452137: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 8s 19ms/step - loss: 0.4884 - accuracy: 0.8413 - val_loss: 0.3323 - val_accuracy: 0.8903\n",
      "Epoch 2/20\n",
      "404/404 [==============================] - 8s 19ms/step - loss: 0.2969 - accuracy: 0.8973 - val_loss: 0.3421 - val_accuracy: 0.8727\n",
      "Epoch 3/20\n",
      "404/404 [==============================] - 8s 19ms/step - loss: 0.2371 - accuracy: 0.9164 - val_loss: 0.2160 - val_accuracy: 0.9275\n",
      "Epoch 4/20\n",
      "404/404 [==============================] - 8s 19ms/step - loss: 0.2059 - accuracy: 0.9291 - val_loss: 0.2229 - val_accuracy: 0.9229\n",
      "Epoch 5/20\n",
      "404/404 [==============================] - 8s 19ms/step - loss: 0.1776 - accuracy: 0.9379 - val_loss: 0.2491 - val_accuracy: 0.9043\n",
      "Epoch 6/20\n",
      "404/404 [==============================] - 8s 19ms/step - loss: 0.1599 - accuracy: 0.9408 - val_loss: 0.1887 - val_accuracy: 0.9368\n",
      "Epoch 7/20\n",
      "404/404 [==============================] - 7s 19ms/step - loss: 0.1461 - accuracy: 0.9480 - val_loss: 0.1899 - val_accuracy: 0.9346\n",
      "Epoch 8/20\n",
      "404/404 [==============================] - 8s 19ms/step - loss: 0.1325 - accuracy: 0.9528 - val_loss: 0.2126 - val_accuracy: 0.9371\n",
      "Epoch 9/20\n",
      "404/404 [==============================] - 8s 19ms/step - loss: 0.1222 - accuracy: 0.9537 - val_loss: 0.1628 - val_accuracy: 0.9458\n",
      "Epoch 10/20\n",
      "404/404 [==============================] - 8s 19ms/step - loss: 0.1144 - accuracy: 0.9602 - val_loss: 0.1728 - val_accuracy: 0.9402\n",
      "Epoch 11/20\n",
      "404/404 [==============================] - 8s 19ms/step - loss: 0.1054 - accuracy: 0.9611 - val_loss: 0.2410 - val_accuracy: 0.9226\n",
      "Epoch 12/20\n",
      "404/404 [==============================] - 8s 19ms/step - loss: 0.1002 - accuracy: 0.9648 - val_loss: 0.1784 - val_accuracy: 0.9430\n",
      "Epoch 13/20\n",
      "404/404 [==============================] - 7s 19ms/step - loss: 0.0871 - accuracy: 0.9693 - val_loss: 0.1876 - val_accuracy: 0.9362\n",
      "Epoch 14/20\n",
      "404/404 [==============================] - 7s 19ms/step - loss: 0.0887 - accuracy: 0.9676 - val_loss: 0.2374 - val_accuracy: 0.9287\n",
      "Epoch 15/20\n",
      "404/404 [==============================] - 7s 19ms/step - loss: 0.0871 - accuracy: 0.9683 - val_loss: 0.1807 - val_accuracy: 0.9424\n",
      "Epoch 16/20\n",
      "404/404 [==============================] - 7s 18ms/step - loss: 0.0644 - accuracy: 0.9782 - val_loss: 0.2709 - val_accuracy: 0.9346\n",
      "Epoch 17/20\n",
      "404/404 [==============================] - 7s 19ms/step - loss: 0.0685 - accuracy: 0.9747 - val_loss: 0.2147 - val_accuracy: 0.9418\n",
      "Epoch 18/20\n",
      "404/404 [==============================] - 7s 18ms/step - loss: 0.0538 - accuracy: 0.9796 - val_loss: 0.2422 - val_accuracy: 0.9247\n",
      "Epoch 19/20\n",
      "404/404 [==============================] - 7s 19ms/step - loss: 0.0533 - accuracy: 0.9794 - val_loss: 0.2101 - val_accuracy: 0.9458\n",
      "Epoch 20/20\n",
      "404/404 [==============================] - 7s 18ms/step - loss: 0.0429 - accuracy: 0.9845 - val_loss: 0.2410 - val_accuracy: 0.9387\n",
      "___Training____\n",
      "accuracy 97.6 ,precision 99.2, recall 98.5,f1_score 98.8 \n",
      "___Validation____\n",
      "accuracy 75.1 ,precision 90.8, recall 80.5, f1_score 84.6 \n",
      "101/101 [==============================] - 0s 4ms/step - loss: 0.2410 - accuracy: 0.9387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-14 20:34:20.762330: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./without_k_fold/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f5d450b4ad0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12914,)\n",
      "(12914,)\n",
      "\n",
      "(3228,)\n",
      "(3228,)\n",
      "validataion_loss 0.241, validation_accuracy 93.89999999999999\n"
     ]
    }
   ],
   "source": [
    "train_preds,train_gt,test_preds,test_gt,loss_acc,c_matrix = Network(X_train,y_train,X_valid, y_valid)\n",
    "\n",
    "print(train_preds.shape)\n",
    "print(train_gt.shape)\n",
    "print()\n",
    "\n",
    "print(test_preds.shape)\n",
    "print(test_gt.shape)\n",
    "#print(scores)\n",
    "\n",
    "val_loss,val_acc = loss_acc[-1]\n",
    "print(f'validataion_loss {round(val_loss,3)}, validation_accuracy {round(val_acc,3)*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f53c17",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "324277f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training RESULTS: \n",
      "\n",
      "Avg. Accuracy: 0.9763667675887608\n",
      "Avg. Precision: 0.9915311667513851\n",
      "Avg. Recall: 0.9846684481394906\n",
      "Avg. F1: 0.9879248469592117\n",
      "\n",
      "Training RESULTS (PER CLASS): \n",
      "\n",
      "Accuracy:\n",
      "   dribbling: 99.49322577308925 %\n",
      "   shot: 98.69727047146401 %\n",
      "   pass: 95.03042596348884 %\n",
      "   layup: 99.84051036682615 %\n",
      "   rebound: 95.1219512195122 %\n",
      "\n",
      "Precision:\n",
      "   dribbling: 99.76148501503681 %\n",
      "   shot: 100.0 %\n",
      "   pass: 96.00409836065575 %\n",
      "   layup: 100.0 %\n",
      "   rebound: 100.0 %\n",
      "\n",
      "Recall:\n",
      "   dribbling: 99.73045822102425 %\n",
      "   shot: 98.69727047146401 %\n",
      "   pass: 98.9440337909187 %\n",
      "   layup: 99.84051036682615 %\n",
      "   rebound: 95.1219512195122 %\n",
      "\n",
      "F1:\n",
      "   dribbling: 99.74596920524651 %\n",
      "   shot: 99.344364658133 %\n",
      "   pass: 97.45189807592305 %\n",
      "   layup: 99.92019154030328 %\n",
      "   rebound: 97.5 %\n"
     ]
    }
   ],
   "source": [
    "cls = np.array(range(5))\n",
    "class_names = ['dribbling','shot','pass','layup','rebound']\n",
    "\n",
    "print('\\nTraining RESULTS: ')\n",
    "print(\"\\nAvg. Accuracy: {0}\".format(jaccard_score(train_gt, train_preds, average='macro')))\n",
    "print(\"Avg. Precision: {0}\".format(precision_score(train_gt, train_preds, average='macro')))\n",
    "print(\"Avg. Recall: {0}\".format(recall_score(train_gt, train_preds, average='macro')))\n",
    "print(\"Avg. F1: {0}\".format(f1_score(train_gt, train_preds, average='macro')))\n",
    "\n",
    "print(\"\\nTraining RESULTS (PER CLASS): \")\n",
    "print(\"\\nAccuracy:\")\n",
    "for i, rslt in enumerate(jaccard_score(train_gt, train_preds, average=None, labels=cls)):\n",
    "    print(\"   {0}: {1} %\".format(class_names[i], rslt*100))\n",
    "print(\"\\nPrecision:\")\n",
    "for i, rslt in enumerate(precision_score(train_gt, train_preds, average=None, labels=cls)):\n",
    "    print(\"   {0}: {1} %\".format(class_names[i], rslt*100))\n",
    "print(\"\\nRecall:\")\n",
    "for i, rslt in enumerate(recall_score(train_gt, train_preds, average=None, labels=cls)):\n",
    "    print(\"   {0}: {1} %\".format(class_names[i], rslt*100))\n",
    "print(\"\\nF1:\")\n",
    "for i, rslt in enumerate(f1_score(train_gt, train_preds, average=None, labels=cls)):\n",
    "    print(\"   {0}: {1} %\".format(class_names[i], rslt*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf08611",
   "metadata": {},
   "source": [
    "# Validation Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "364189ea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation RESULTS: \n",
      "\n",
      "Avg. Accuracy: 0.7513672746959177\n",
      "Avg. Precision: 0.9082467170018422\n",
      "Avg. Recall: 0.8046479374546267\n",
      "Avg. F1: 0.8464381806604953\n",
      "\n",
      "VALIDATION RESULTS (PER CLASS): \n",
      "\n",
      "Accuracy:\n",
      "dribbling: 93.0\n",
      "shot: 85.0\n",
      "pass: 56.00000000000001\n",
      "layup: 89.0\n",
      "rebound: 52.0\n",
      "\n",
      "Precision:\n",
      "dribbling: 95.0\n",
      "shot: 97.0\n",
      "pass: 72.0\n",
      "layup: 98.0\n",
      "rebound: 92.0\n",
      "\n",
      "Recall:\n",
      "dribbling: 98.0\n",
      "shot: 87.0\n",
      "pass: 72.0\n",
      "layup: 91.0\n",
      "rebound: 55.00000000000001\n",
      "\n",
      "F1:\n",
      "dribbling: 96.0\n",
      "shot: 92.0\n",
      "pass: 72.0\n",
      "layup: 94.0\n",
      "rebound: 69.0\n",
      "\n",
      "GENERALIZATION GAP ANALYSIS: \n",
      "\n",
      "Train-Val-Accuracy Difference: 0.22499949289284316\n",
      "Train-Val-Precision Difference: 0.08328444974954285\n",
      "Train-Val-Recall Difference: 0.1800205106848639\n",
      "Train-Val-F1 Difference: 0.14148666629871642\n"
     ]
    }
   ],
   "source": [
    "print('\\nValidation RESULTS: ')\n",
    "print(\"\\nAvg. Accuracy: {0}\".format(jaccard_score(test_gt, test_preds, average='macro')))\n",
    "print(\"Avg. Precision: {0}\".format(precision_score(test_gt, test_preds, average='macro')))\n",
    "print(\"Avg. Recall: {0}\".format(recall_score(test_gt, test_preds, average='macro')))\n",
    "print(\"Avg. F1: {0}\".format(f1_score(test_gt, test_preds, average='macro')))\n",
    "\n",
    "print(\"\\nVALIDATION RESULTS (PER CLASS): \")\n",
    "print(\"\\nAccuracy:\")\n",
    "for i, rslt in enumerate(jaccard_score(test_gt, test_preds, average=None, labels=cls)):\n",
    "    print(f'{class_names[i]}: {round(rslt,2)*100}')\n",
    "    #print(\"   {0}: {1} %\".format(class_names[i], rslt*100))\n",
    "print(\"\\nPrecision:\")\n",
    "for i, rslt in enumerate(precision_score(test_gt, test_preds, average=None, labels=cls)):\n",
    "    print(f'{class_names[i]}: {round(rslt,2)*100}')\n",
    "    #print(\"   {0}: {1} %\".format(class_names[i], rslt*100))\n",
    "print(\"\\nRecall:\")\n",
    "for i, rslt in enumerate(recall_score(test_gt, test_preds, average=None, labels=cls)):\n",
    "    print(f'{class_names[i]}: {round(rslt,2)*100}')\n",
    "    #print(\"   {0}: {1} %\".format(class_names[i], rslt*100))\n",
    "print(\"\\nF1:\")\n",
    "for i, rslt in enumerate(f1_score(test_gt, test_preds, average=None, labels=cls)):\n",
    "    print(f'{class_names[i]}: {round(rslt,2)*100}')\n",
    "    #print(\"   {0}: {1} %\".format(class_names[i], rslt*100))\n",
    "    \n",
    "print(\"\\nGENERALIZATION GAP ANALYSIS: \")\n",
    "print(\"\\nTrain-Val-Accuracy Difference: {0}\".format(jaccard_score(train_gt, train_preds, average='macro') -\n",
    "                                                  jaccard_score(test_gt, test_preds, average='macro')))\n",
    "print(\"Train-Val-Precision Difference: {0}\".format(precision_score(train_gt, train_preds, average='macro') -\n",
    "                                                   precision_score(test_gt, test_preds, average='macro')))\n",
    "print(\"Train-Val-Recall Difference: {0}\".format(recall_score(train_gt, train_preds, average='macro') -\n",
    "                                                recall_score(test_gt, test_preds, average='macro')))\n",
    "print(\"Train-Val-F1 Difference: {0}\".format(f1_score(train_gt, train_preds, average='macro') -\n",
    "                                            f1_score(test_gt, test_preds, average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ef3e5a",
   "metadata": {},
   "source": [
    "# Testing on Game data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2db2a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game_data (45111, 6)\n",
      "data_labelled_game  (45111, 4)\n",
      "(45111, 3) (45111,)\n",
      "\n",
      "Shape of the X_train_game and y_train_game datasets after windowing: \n",
      "(1186, 50, 3) (1186,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shk/anaconda3/envs/adversarial/lib/python3.7/site-packages/ipykernel_launcher.py:20: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n"
     ]
    }
   ],
   "source": [
    "print('game_data',game_data.shape)\n",
    "\n",
    "label_game = game_data['basketball']\n",
    "x_axis_game = sorted(label_game.unique())\n",
    "y_axis_game = label_game.value_counts()\n",
    "\n",
    "X_game = game_data.iloc[:,:-1]\n",
    "\n",
    "def labelling(clean_data,data_y):\n",
    "    clean_data[data_y == 'dribbling'] = 0\n",
    "    clean_data[data_y == 'shot'] = 1\n",
    "    clean_data[data_y == 'pass'] = 2\n",
    "    clean_data[data_y == 'layup'] = 3\n",
    "    clean_data[data_y == 'rebound'] = 4\n",
    "    \n",
    "    return data_y\n",
    "\n",
    "y_game = labelling(game_data,game_data.iloc[:,-1]).astype(int)\n",
    "\n",
    "data_labelled_game = np.concatenate((X_game, y_game[:,None]), axis=1)[:,2:] #669204, 6\n",
    "print('data_labelled_game ',data_labelled_game.shape)\n",
    "\n",
    "data_labelled_X = data_labelled_game[:,:-1]\n",
    "data_labelled_Y = data_labelled_game[:,-1]\n",
    "\n",
    "print(data_labelled_X.shape,data_labelled_Y.shape)\n",
    "sw_length = 50\n",
    "sw_overlap = 25\n",
    "\n",
    "X_train_game, y_train_game = apply_sliding_window(data_labelled_X, data_labelled_Y, sliding_window_size=sw_length, \n",
    "                                        sampling_rate=50,sliding_window_overlap=sw_overlap)\n",
    "\n",
    "\n",
    "X_train_game, y_train_game = X_train_game.astype(np.float32), y_train_game[:,0].astype(np.uint8)\n",
    "\n",
    "print(\"\\nShape of the X_train_game and y_train_game datasets after windowing: \")\n",
    "print(X_train_game.shape, y_train_game.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745478d2",
   "metadata": {},
   "source": [
    "# Loading the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e9e32b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f5d25fafa90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model('./Pre_Trained_models/without_k_fold')\n",
    "\n",
    "pt = './Pre_Trained_models/without_k_fold/without_k_fold'\n",
    "model.load_weights(pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30f7d263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/505 [==============================] - 2s 4ms/step - loss: 0.0631 - accuracy: 0.9839\n",
      "___DRILL___\n",
      "DRILL_loss 0.063, Drill_accuracy 98.4\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2023.2369 - accuracy: 0.3010\n",
      "___GAME___\n",
      "GAME_loss 2023.237, GAME_accuracy 30.099999999999998\n"
     ]
    }
   ],
   "source": [
    "X_tt = data_X\n",
    "y_tt = data_Y\n",
    "loss_drill,acc_drill = model.evaluate(X_tt,y_tt)\n",
    "\n",
    "print('___DRILL___')\n",
    "print(f'DRILL_loss {round(loss_drill,3)}, Drill_accuracy {round(acc_drill,3)*100}')\n",
    "\n",
    "#X_tt = data_X\n",
    "#y_tt = data_Y\n",
    "loss_game,acc_game = model.evaluate(X_train_game,y_train_game)\n",
    "\n",
    "print('___GAME___')\n",
    "print(f'GAME_loss {round(loss_game,3)}, GAME_accuracy {round(acc_game,3)*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c3a6c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___GAME____\n",
      "accuracy 15.4 ,precision 26.1, recall 29.4,f1_score 25.900000000000002 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred_game = np.argmax(model.predict(X_train_game), axis=-1)\n",
    "\n",
    "#Training\n",
    "acc_game = jaccard_score(y_train_game, y_pred_game, average='macro')\n",
    "pre_game = precision_score(y_train_game, y_pred_game, average='macro', zero_division=0)\n",
    "reca_game = recall_score(y_train_game, y_pred_game, average='macro', zero_division=0)\n",
    "f1_game = f1_score(y_train_game, y_pred_game, average='macro', zero_division=0)\n",
    "\n",
    "print(\"___GAME____\")\n",
    "print(f\"accuracy {round(acc_game,3)*100} ,precision {round(pre_game,3)*100}, recall {round(reca_game,3)*100},f1_score {round(f1_game,3)*100} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c558449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Game RESULTS: \n",
      "\n",
      "Avg. Accuracy: 0.1538711331959549\n",
      "Avg. Precision: 0.2610529254281275\n",
      "Avg. Recall: 0.29410973562860565\n",
      "Avg. F1: 0.25934556345335896\n",
      "\n",
      "GAME RESULTS (PER CLASS): \n",
      "\n",
      "Accuracy:\n",
      "dribbling: 27.0\n",
      "shot: 10.0\n",
      "pass: 13.0\n",
      "layup: 21.0\n",
      "rebound: 6.0\n",
      "\n",
      "Precision:\n",
      "dribbling: 51.0\n",
      "shot: 14.000000000000002\n",
      "pass: 27.0\n",
      "layup: 26.0\n",
      "rebound: 12.0\n",
      "\n",
      "Recall:\n",
      "dribbling: 37.0\n",
      "shot: 31.0\n",
      "pass: 19.0\n",
      "layup: 50.0\n",
      "rebound: 10.0\n",
      "\n",
      "F1:\n",
      "dribbling: 43.0\n",
      "shot: 19.0\n",
      "pass: 22.0\n",
      "layup: 34.0\n",
      "rebound: 11.0\n"
     ]
    }
   ],
   "source": [
    "print('\\nGame RESULTS: ')\n",
    "print(\"\\nAvg. Accuracy: {0}\".format(jaccard_score(y_train_game, y_pred_game, average='macro')))\n",
    "print(\"Avg. Precision: {0}\".format(precision_score(y_train_game, y_pred_game, average='macro')))\n",
    "print(\"Avg. Recall: {0}\".format(recall_score(y_train_game, y_pred_game, average='macro')))\n",
    "print(\"Avg. F1: {0}\".format(f1_score(y_train_game, y_pred_game, average='macro')))\n",
    "\n",
    "print(\"\\nGAME RESULTS (PER CLASS): \")\n",
    "print(\"\\nAccuracy:\")\n",
    "for i, rslt in enumerate(jaccard_score(y_train_game, y_pred_game, average=None, labels=cls)):\n",
    "    print(f'{class_names[i]}: {round(rslt,2)*100}')\n",
    "    #print(\"   {0}: {1} %\".format(class_names[i], rslt*100))\n",
    "print(\"\\nPrecision:\")\n",
    "for i, rslt in enumerate(precision_score(y_train_game, y_pred_game, average=None, labels=cls)):\n",
    "    print(f'{class_names[i]}: {round(rslt,2)*100}')\n",
    "    #print(\"   {0}: {1} %\".format(class_names[i], rslt*100))\n",
    "print(\"\\nRecall:\")\n",
    "for i, rslt in enumerate(recall_score(y_train_game, y_pred_game, average=None, labels=cls)):\n",
    "    print(f'{class_names[i]}: {round(rslt,2)*100}')\n",
    "    #print(\"   {0}: {1} %\".format(class_names[i], rslt*100))\n",
    "print(\"\\nF1:\")\n",
    "for i, rslt in enumerate(f1_score(y_train_game, y_pred_game, average=None, labels=cls)):\n",
    "    print(f'{class_names[i]}: {round(rslt,2)*100}')\n",
    "    #print(\"   {0}: {1} %\".format(class_names[i], rslt*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7939d3",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
