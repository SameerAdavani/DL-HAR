{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45594d6f",
   "metadata": {},
   "source": [
    "\n",
    "# LOCOMOTION Activity Recognition using LSTM Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ec0972",
   "metadata": {},
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abcebe99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-15 00:45:39.999222: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-15 00:45:39.999245: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/shk/anaconda3/envs/adversarial/lib/python3.7/site-packages/ipykernel_launcher.py:33: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before_game 2710751\n",
      "new_data (1982320, 6)\n",
      "____\n",
      "game_data (728431, 6)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, jaccard_score,confusion_matrix, plot_confusion_matrix\n",
    "import time\n",
    "from typing import Any\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, LSTM\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, RepeatedKFold\n",
    "from sklearn.metrics import f1_score, confusion_matrix, plot_confusion_matrix\n",
    "from pandas import DataFrame\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "files = glob.glob('/data/shk/dl-for-har/tutorial_notebooks/Prof_New/*.csv')\n",
    "\n",
    "name = [file.split('/')[-1] for file in files]\n",
    "df = pd.concat(map(pd.read_csv,files),ignore_index = True) #4230213 rows × 10 columns\n",
    "\n",
    "data = df\n",
    "\n",
    "clean_data = data[data['locomotion']!='not_labeled']\n",
    "clean_data = clean_data[data['locomotion'].notna()]\n",
    "clean_data['locomotion'].replace({'layup':'jumping'},inplace=True)\n",
    "print('Before_game',len(clean_data))\n",
    "\n",
    "new_data = clean_data[clean_data.coarse != 'game'] #623758 rows × 10 columns\n",
    "new_data = new_data.drop(columns='coarse')\n",
    "new_data = new_data.drop(columns='basketball')\n",
    "new_data = new_data.iloc[:,:6]\n",
    "print('new_data',new_data.shape)\n",
    "print('____')\n",
    "\n",
    "game_data = clean_data[clean_data.coarse == 'game']\n",
    "game_data = game_data.drop(columns='coarse')\n",
    "game_data = game_data.drop(columns='basketball')\n",
    "game_data = game_data.iloc[:,:6] #45446 rows × 6 columns\n",
    "print('game_data',game_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeef8f8b",
   "metadata": {},
   "source": [
    "# Labelling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e80649a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shk/anaconda3/envs/adversarial/lib/python3.7/site-packages/ipykernel_launcher.py:22: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n"
     ]
    }
   ],
   "source": [
    "label = new_data['locomotion']\n",
    "x_axis = sorted(label.unique())\n",
    "y_axis = label.value_counts()\n",
    "\n",
    "X = new_data.iloc[:,:-1]#.astype(np.float32)\n",
    "\n",
    "class_names = ['walking','running','standing','sitting','jumping']\n",
    "num_classes = len(class_names)\n",
    "\n",
    "def labelling(clean_data,data_y):\n",
    "    clean_data[data_y == 'walking'] = 0\n",
    "    clean_data[data_y == 'running'] = 1\n",
    "    clean_data[data_y == 'standing'] = 2\n",
    "    clean_data[data_y == 'sitting'] = 3\n",
    "    clean_data[data_y == 'jumping'] = 4\n",
    "    \n",
    "    return data_y\n",
    "\n",
    "y = labelling(new_data,new_data.iloc[:,-1]).astype(int)\n",
    "\n",
    "\n",
    "data_labelled = np.concatenate((X, y[:,None]), axis=1)[:,1:] #669204, 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55422ef",
   "metadata": {},
   "source": [
    "# Special preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3e3a792",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_walking = data_labelled[data_labelled[:,-1] == 0]\n",
    "data_running = data_labelled[data_labelled[:,-1] == 1]\n",
    "data_standing = data_labelled[data_labelled[:,-1] == 2]\n",
    "data_sitting = data_labelled[data_labelled[:,-1] == 3]\n",
    "data_jumping = data_labelled[data_labelled[:,-1] == 4]\n",
    "\n",
    "\n",
    "def spilt(data):\n",
    "\n",
    "    dd = np.asarray(data)\n",
    "    T = int(0.8* len(dd))\n",
    "    train_size = int(T)\n",
    "    test_size = len(dd) - train_size\n",
    "\n",
    "    train_df,test_df = torch.utils.data.random_split(dd, [train_size,test_size])\n",
    "    X = train_df[:][:,0:4]\n",
    "    Y = train_df[:][:,4]\n",
    "\n",
    "    X_v = test_df[:][:,0:4]\n",
    "    y_v = test_df[:][:,4]\n",
    "    \n",
    "    return X,Y,X_v,y_v\n",
    "\n",
    "X_walking,Y_walking,X_v_walking,y_v_walking = spilt(data_walking)\n",
    "X_running,Y_running,X_v_running,y_v_running = spilt(data_running)\n",
    "X_standing,Y_standing,X_v_standing,y_v_standing = spilt(data_standing)\n",
    "X_sitting,Y_sitting,X_v_sitting,y_v_sitting = spilt(data_sitting)\n",
    "X_jumping,Y_jumping,X_v_jumping,y_v_jumping = spilt(data_jumping)\n",
    "\n",
    "\n",
    "X = np.concatenate((X_walking, X_running,X_standing,X_sitting,X_jumping), axis=0)[:,1:]\n",
    "Y = np.concatenate((Y_walking, Y_running,Y_standing,Y_sitting,Y_jumping), axis=0)\n",
    "\n",
    "X_v = np.concatenate((X_v_walking, X_v_running,X_v_standing,X_v_sitting,X_v_jumping), axis=0)[:,1:]\n",
    "y_v = np.concatenate((y_v_walking, y_v_running,y_v_standing,y_v_sitting,y_v_jumping), axis=0)\n",
    "\n",
    "train_data = np.column_stack((X,Y))\n",
    "valid_data = np.column_stack((X_v,y_v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bd4572",
   "metadata": {},
   "source": [
    "# Sliding Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d4448c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of the X_train and Y_train datasets after windowing: \n",
      "(41732, 50, 3) (41732, 50)\n",
      "\n",
      "Shape of the X_valid and y_valid datasets after windowing: \n",
      "(10432, 50, 3) (10432, 50)\n",
      "\n",
      "Shape of the X after windowing: \n",
      "(52164, 50, 3)\n",
      "\n",
      "Shape of the Y after windowing: \n",
      "(52164,)\n"
     ]
    }
   ],
   "source": [
    "def sliding_window(data, samples_per_window, overlap_ratio):\n",
    "    windows = []\n",
    "    indices = []\n",
    "    curr = 0\n",
    "    win_len = int(samples_per_window)\n",
    "    \n",
    "    if overlap_ratio is not None:\n",
    "        overlapping_elements = int((overlap_ratio / 100) * (win_len))\n",
    "        if overlapping_elements >= win_len:\n",
    "            print('Number of overlapping elements exceeds window size.')\n",
    "            return\n",
    "    while curr < len(data) - win_len:\n",
    "        windows.append(data[curr:curr + win_len])\n",
    "        indices.append([curr, curr + win_len])\n",
    "        curr = curr + win_len - overlapping_elements\n",
    "    try:\n",
    "        result_windows = np.array(windows)\n",
    "        result_indices = np.array(indices)\n",
    "    except:\n",
    "        result_windows = np.empty(shape=(len(windows), win_len, data.shape[1]), dtype=object)\n",
    "        result_indices = np.array(indices)\n",
    "        for i in range(0, len(windows)):\n",
    "            result_windows[i] = windows[i]\n",
    "            result_indices[i] = indices[i]\n",
    "    return result_windows, result_indices\n",
    "\n",
    "def apply_sliding_window(data_x, data_y, sliding_window_size, sampling_rate, sliding_window_overlap):\n",
    "    \n",
    "    output_x, _ = sliding_window(data_x, sliding_window_size, sliding_window_overlap)\n",
    "    output_y, _ = sliding_window(data_y, sliding_window_size, sliding_window_overlap)\n",
    "\n",
    "    return output_x,output_y\n",
    "\n",
    "sw_length = 50\n",
    "sw_overlap = 25\n",
    "\n",
    "X_train, y_train = apply_sliding_window(X, Y, sw_length, sampling_rate=50,sliding_window_overlap=sw_overlap)\n",
    "X_valid, y_valid = apply_sliding_window(X_v, y_v, sw_length, sampling_rate=50,sliding_window_overlap=sw_overlap)\n",
    "\n",
    "\n",
    "X_train, y_train = X_train.astype(np.float32), y_train.astype(np.uint8)\n",
    "X_valid, y_valid = X_valid.astype(np.float32), y_valid.astype(np.uint8)\n",
    "\n",
    "print(\"\\nShape of the X_train and Y_train datasets after windowing: \")\n",
    "print(X_train.shape, y_train.shape) \n",
    "\n",
    "print(\"\\nShape of the X_valid and y_valid datasets after windowing: \")\n",
    "print(X_valid.shape, y_valid.shape)\n",
    "\n",
    "y_train = y_train[:,0]\n",
    "y_valid = y_valid[:,0]\n",
    "\n",
    "data_X = np.concatenate((X_train,X_valid),axis=0) \n",
    "\n",
    "print(\"\\nShape of the X after windowing: \")\n",
    "print(data_X.shape)\n",
    "\n",
    "print(\"\\nShape of the Y after windowing: \")\n",
    "data_Y = np.concatenate((y_train,y_valid),axis=0) \n",
    "print(data_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920efc43",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff78886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Network(X_train,y_train,X_valid, y_valid):\n",
    "\n",
    "    train_preds = []\n",
    "    train_gt = []\n",
    "    test_preds = []\n",
    "    test_gt = []   \n",
    "    loss_acc = []\n",
    "    c_matrix =[]\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=26,input_shape=[X_train.shape[1], X_train.shape[2]], activation = 'relu', return_sequences = True))\n",
    "    model.add(Dropout(rate=0.1))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=5000, activation='relu'))\n",
    "    model.add(Dropout(rate=0.2))\n",
    "    model.add(Dense(units=2000, activation='relu'))\n",
    "    model.add(Dense(units=800, activation='relu'))\n",
    "    model.add(Dropout(rate=0.3))\n",
    "    model.add(Dense(units=5, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "                  metrics=['accuracy'])\n",
    "   \n",
    "    model.fit(X_train,y_train,epochs=4, validation_data=(X_valid,y_valid),verbose=1)\n",
    "\n",
    "    y_pred_train = np.argmax(model.predict(X_train), axis=-1)\n",
    "    y_pred_test = np.argmax(model.predict(X_valid), axis=-1)\n",
    "\n",
    "\n",
    "    #Training\n",
    "    acc_train = jaccard_score(y_train, y_pred_train, average='macro')\n",
    "    pre_train = precision_score(y_train, y_pred_train, average='macro', zero_division=0)\n",
    "    reca_train = recall_score(y_train, y_pred_train, average='macro', zero_division=0)\n",
    "    f1_train = f1_score(y_train, y_pred_train, average='macro', zero_division=0)\n",
    "\n",
    "    train_preds = np.concatenate((np.array(train_preds, int), np.array(y_pred_train, int)))\n",
    "    train_gt = np.concatenate((np.array(train_gt, int), np.array(y_train, int)))\n",
    "\n",
    "    print(\"___Training____\")\n",
    "    print(f\"accuracy {round(acc_train,3)*100} ,precision {round(pre_train,3)*100}, recall {round(reca_train,3)*100},f1_score {round(f1_train,3)*100} \")\n",
    "\n",
    "    #Validation\n",
    "    acc_test = jaccard_score(y_valid, y_pred_test, average='macro')\n",
    "    pre_test = precision_score(y_valid, y_pred_test, average='macro', zero_division=0)\n",
    "    reca_test = recall_score(y_valid, y_pred_test, average='macro', zero_division=0)\n",
    "    f1_test = f1_score(y_valid, y_pred_test, average='macro', zero_division=0)\n",
    "\n",
    "    test_preds = np.concatenate((np.array(test_preds, int), np.array(y_pred_test, int)))\n",
    "    test_gt = np.concatenate((np.array(test_gt, int), np.array(y_valid, int)))\n",
    "\n",
    "    print(\"___Validation____\")\n",
    "    print(f\"accuracy {round(acc_test,3)*100} ,precision {round(pre_test,3)*100}, recall {round(reca_test,3)*100}, f1_score {round(f1_test,3)*100} \")\n",
    "\n",
    "        #Graphs\n",
    "    loss_acc.append(model.evaluate(X_valid,y_valid))\n",
    "    c_matrix.append(confusion_matrix(y_valid, y_pred_test))   \n",
    "      \n",
    "\n",
    "    #Save Weights\n",
    "    model.save_weights('./Pre_Trained_models/locomotion_without_k_fold/locomotion_without_k_fold',overwrite=True)\n",
    "    model.save('./Pre_Trained_models/locomotion_without_k_fold',overwrite=True)\n",
    "    \n",
    "    return train_preds,train_gt,test_preds,test_gt,loss_acc,c_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "368e7c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1305/1305 [==============================] - 71s 54ms/step - loss: 0.4361 - accuracy: 0.8510 - val_loss: 0.2413 - val_accuracy: 0.8965\n",
      "Epoch 2/4\n",
      "1305/1305 [==============================] - 71s 54ms/step - loss: 0.2215 - accuracy: 0.9119 - val_loss: 0.2137 - val_accuracy: 0.9198\n",
      "Epoch 3/4\n",
      "1305/1305 [==============================] - 71s 55ms/step - loss: 0.1840 - accuracy: 0.9285 - val_loss: 0.1895 - val_accuracy: 0.9276\n",
      "Epoch 4/4\n",
      "1305/1305 [==============================] - 68s 52ms/step - loss: 0.1647 - accuracy: 0.9358 - val_loss: 0.1478 - val_accuracy: 0.9462\n",
      "___Training____\n",
      "accuracy 85.3 ,precision 92.0, recall 91.2,f1_score 91.5 \n",
      "___Validation____\n",
      "accuracy 85.3 ,precision 91.4, recall 91.7, f1_score 91.5 \n",
      "326/326 [==============================] - 2s 8ms/step - loss: 0.1478 - accuracy: 0.9462\n",
      "INFO:tensorflow:Assets written to: ./locomotion_without_k_fold/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./locomotion_without_k_fold/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fa69162bf50> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41732,)\n",
      "(41732,)\n",
      "\n",
      "(10432,)\n",
      "(10432,)\n",
      "validataion_loss 0.148, validation_accuracy 94.6\n"
     ]
    }
   ],
   "source": [
    "train_preds,train_gt,test_preds,test_gt,loss_acc,c_matrix = Network(X_train,y_train,X_valid, y_valid)\n",
    "\n",
    "print(train_preds.shape)\n",
    "print(train_gt.shape)\n",
    "print()\n",
    "\n",
    "print(test_preds.shape)\n",
    "print(test_gt.shape)\n",
    "#print(scores)\n",
    "\n",
    "val_loss,val_acc = loss_acc[-1]\n",
    "print(f'validataion_loss {round(val_loss,3)}, validation_accuracy {round(val_acc,3)*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f53c17",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b3a5a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training RESULTS: \n",
      "\n",
      "Avg. Accuracy: 0.8530709483087472\n",
      "Avg. Precision: 0.9196178390191317\n",
      "Avg. Recall: 0.9118724348346505\n",
      "Avg. F1: 0.9146087810258351\n",
      "\n",
      "Training RESULTS (PER CLASS): \n",
      "\n",
      "Accuracy:\n",
      "   walking: 90.65148946476145 %\n",
      "   running: 97.73949701991569 %\n",
      "   standing: 66.16782469267771 %\n",
      "   sitting: 99.96527777777777 %\n",
      "   jumping: 72.01138519924099 %\n",
      "\n",
      "Precision:\n",
      "   walking: 96.27057613168725 %\n",
      "   running: 98.45511787963098 %\n",
      "   standing: 75.71865443425077 %\n",
      "   sitting: 99.96527777777777 %\n",
      "   jumping: 89.39929328621908 %\n",
      "\n",
      "Recall:\n",
      "   walking: 93.95080321285141 %\n",
      "   running: 99.26182918727393 %\n",
      "   standing: 83.98914518317503 %\n",
      "   sitting: 100.0 %\n",
      "   jumping: 78.7344398340249 %\n",
      "\n",
      "F1:\n",
      "   walking: 95.09654471544717 %\n",
      "   running: 98.85682778900939 %\n",
      "   standing: 79.63975554840785 %\n",
      "   sitting: 99.98263587428373 %\n",
      "   jumping: 83.72862658576945 %\n"
     ]
    }
   ],
   "source": [
    "cls = np.array(range(5))\n",
    "class_names = ['walking','running','standing','sitting','jumping']\n",
    "\n",
    "print('\\nTraining RESULTS: ')\n",
    "print(\"\\nAvg. Accuracy: {0}\".format(jaccard_score(train_gt, train_preds, average='macro')))\n",
    "print(\"Avg. Precision: {0}\".format(precision_score(train_gt, train_preds, average='macro')))\n",
    "print(\"Avg. Recall: {0}\".format(recall_score(train_gt, train_preds, average='macro')))\n",
    "print(\"Avg. F1: {0}\".format(f1_score(train_gt, train_preds, average='macro')))\n",
    "\n",
    "print(\"\\nTraining RESULTS (PER CLASS): \")\n",
    "print(\"\\nAccuracy:\")\n",
    "for i, rslt in enumerate(jaccard_score(train_gt, train_preds, average=None, labels=cls)):\n",
    "    print(\"   {0}: {1} %\".format(class_names[i], rslt*100))\n",
    "print(\"\\nPrecision:\")\n",
    "for i, rslt in enumerate(precision_score(train_gt, train_preds, average=None, labels=cls)):\n",
    "    print(\"   {0}: {1} %\".format(class_names[i], rslt*100))\n",
    "print(\"\\nRecall:\")\n",
    "for i, rslt in enumerate(recall_score(train_gt, train_preds, average=None, labels=cls)):\n",
    "    print(\"   {0}: {1} %\".format(class_names[i], rslt*100))\n",
    "print(\"\\nF1:\")\n",
    "for i, rslt in enumerate(f1_score(train_gt, train_preds, average=None, labels=cls)):\n",
    "    print(\"   {0}: {1} %\".format(class_names[i], rslt*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca53cc3",
   "metadata": {},
   "source": [
    "# Validation Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "364189ea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation RESULTS: \n",
      "\n",
      "Avg. Accuracy: 0.8533236148319254\n",
      "Avg. Precision: 0.9144025850680377\n",
      "Avg. Recall: 0.9167798904049302\n",
      "Avg. F1: 0.9148459519029203\n",
      "\n",
      "VALIDATION RESULTS (PER CLASS): \n",
      "\n",
      "Accuracy:\n",
      "walking: 91.0\n",
      "running: 98.0\n",
      "standing: 66.0\n",
      "sitting: 100.0\n",
      "jumping: 72.0\n",
      "\n",
      "Precision:\n",
      "walking: 96.0\n",
      "running: 99.0\n",
      "standing: 75.0\n",
      "sitting: 100.0\n",
      "jumping: 87.0\n",
      "\n",
      "Recall:\n",
      "walking: 94.0\n",
      "running: 99.0\n",
      "standing: 84.0\n",
      "sitting: 100.0\n",
      "jumping: 81.0\n",
      "\n",
      "F1:\n",
      "walking: 95.0\n",
      "running: 99.0\n",
      "standing: 80.0\n",
      "sitting: 100.0\n",
      "jumping: 84.0\n"
     ]
    }
   ],
   "source": [
    "print('\\nValidation RESULTS: ')\n",
    "print(\"\\nAvg. Accuracy: {0}\".format(jaccard_score(test_gt, test_preds, average='macro')))\n",
    "print(\"Avg. Precision: {0}\".format(precision_score(test_gt, test_preds, average='macro')))\n",
    "print(\"Avg. Recall: {0}\".format(recall_score(test_gt, test_preds, average='macro')))\n",
    "print(\"Avg. F1: {0}\".format(f1_score(test_gt, test_preds, average='macro')))\n",
    "\n",
    "print(\"\\nVALIDATION RESULTS (PER CLASS): \")\n",
    "print(\"\\nAccuracy:\")\n",
    "for i, rslt in enumerate(jaccard_score(test_gt, test_preds, average=None, labels=cls)):\n",
    "    print(f'{class_names[i]}: {round(rslt,2)*100}')\n",
    "\n",
    "print(\"\\nPrecision:\")\n",
    "for i, rslt in enumerate(precision_score(test_gt, test_preds, average=None, labels=cls)):\n",
    "    print(f'{class_names[i]}: {round(rslt,2)*100}')\n",
    "\n",
    "print(\"\\nRecall:\")\n",
    "for i, rslt in enumerate(recall_score(test_gt, test_preds, average=None, labels=cls)):\n",
    "    print(f'{class_names[i]}: {round(rslt,2)*100}')\n",
    "\n",
    "print(\"\\nF1:\")\n",
    "for i, rslt in enumerate(f1_score(test_gt, test_preds, average=None, labels=cls)):\n",
    "    print(f'{class_names[i]}: {round(rslt,2)*100}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2705d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GENERALIZATION GAP ANALYSIS: \n",
      "\n",
      "Train-Val-Accuracy Difference: -0.00025266652317823546\n",
      "Train-Val-Precision Difference: 0.005215253951094012\n",
      "Train-Val-Recall Difference: -0.004907455570279717\n",
      "Train-Val-F1 Difference: -0.00023717087708519102\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGENERALIZATION GAP ANALYSIS: \")\n",
    "print(\"\\nTrain-Val-Accuracy Difference: {0}\".format(jaccard_score(train_gt, train_preds, average='macro') -\n",
    "                                                  jaccard_score(test_gt, test_preds, average='macro')))\n",
    "print(\"Train-Val-Precision Difference: {0}\".format(precision_score(train_gt, train_preds, average='macro') -\n",
    "                                                   precision_score(test_gt, test_preds, average='macro')))\n",
    "print(\"Train-Val-Recall Difference: {0}\".format(recall_score(train_gt, train_preds, average='macro') -\n",
    "                                                recall_score(test_gt, test_preds, average='macro')))\n",
    "print(\"Train-Val-F1 Difference: {0}\".format(f1_score(train_gt, train_preds, average='macro') -\n",
    "                                            f1_score(test_gt, test_preds, average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ef3e5a",
   "metadata": {},
   "source": [
    "# Testing on Game data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2db2a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game_data (728431, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shk/anaconda3/envs/adversarial/lib/python3.7/site-packages/ipykernel_launcher.py:21: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_labelled_game  (728431, 4)\n",
      "(728431, 3) (728431,)\n",
      "\n",
      "Shape of the X_train_game and y_train_game datasets after splitting and windowing: \n",
      "(19168, 50, 3) (19168,)\n"
     ]
    }
   ],
   "source": [
    "print('game_data',game_data.shape)\n",
    "\n",
    "label_game = game_data['locomotion']\n",
    "x_axis_game = sorted(label_game.unique())\n",
    "y_axis_game = label_game.value_counts()\n",
    "\n",
    "X_game = game_data.iloc[:,:-1]\n",
    "\n",
    "\n",
    "def adjust_lables(clean_data,data_y):\n",
    "    clean_data[data_y == 'walking'] = 0\n",
    "    clean_data[data_y == 'running'] = 1\n",
    "    clean_data[data_y == 'standing'] = 2\n",
    "    clean_data[data_y == 'sitting'] = 3\n",
    "    clean_data[data_y == 'jumping'] = 4\n",
    "    \n",
    "    return data_y\n",
    "\n",
    "y_game = adjust_lables(game_data,game_data.iloc[:,-1]).astype(int)\n",
    "\n",
    "data_labelled_game = np.concatenate((X_game, y_game[:,None]), axis=1)[:,2:] \n",
    "print('data_labelled_game ',data_labelled_game.shape)\n",
    "\n",
    "data_labelled_X = data_labelled_game[:,:-1]\n",
    "data_labelled_Y = data_labelled_game[:,-1]\n",
    "\n",
    "print(data_labelled_X.shape,data_labelled_Y.shape)\n",
    "\n",
    "X_train_game, y_train_game = apply_sliding_window(data_labelled_X, data_labelled_Y, sliding_window_size=sw_length, \n",
    "                                        sampling_rate=50,sliding_window_overlap=sw_overlap)\n",
    "\n",
    "\n",
    "X_train_game, y_train_game = X_train_game.astype(np.float32), y_train_game[:,0].astype(np.uint8)\n",
    "\n",
    "print(\"\\nShape of the X_train_game and y_train_game datasets after splitting and windowing: \")\n",
    "print(X_train_game.shape, y_train_game.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745478d2",
   "metadata": {},
   "source": [
    "# Loading the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e9e32b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fa5f465cb10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model('./Pre_Trained_models/locomotion_without_k_fold')\n",
    "\n",
    "pt = './Pre_Trained_models/locomotion_without_k_fold/locomotion_without_k_fold'\n",
    "model.load_weights(pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30f7d263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1631/1631 [==============================] - 12s 8ms/step - loss: 0.1433 - accuracy: 0.9467\n",
      "___DRILL___\n",
      "DRILL_loss 0.143, Drill_accuracy 94.69999999999999\n",
      "599/599 [==============================] - 5s 8ms/step - loss: 26.8245 - accuracy: 0.0151\n",
      "___GAME___\n",
      "GAME_loss 26.824, GAME_accuracy 1.5\n"
     ]
    }
   ],
   "source": [
    "X_tt = data_X\n",
    "y_tt = data_Y\n",
    "loss_drill,acc_drill = model.evaluate(X_tt,y_tt)\n",
    "\n",
    "print('___DRILL___')\n",
    "print(f'DRILL_loss {round(loss_drill,3)}, Drill_accuracy {round(acc_drill,3)*100}')\n",
    "\n",
    "#X_tt = data_X\n",
    "#y_tt = data_Y\n",
    "loss_game,acc_game = model.evaluate(X_train_game,y_train_game)\n",
    "\n",
    "print('___GAME___')\n",
    "print(f'GAME_loss {round(loss_game,3)}, GAME_accuracy {round(acc_game,3)*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c3a6c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___GAME____\n",
      "accuracy 1.5 ,precision 2.1, recall 13.100000000000001,f1_score 2.8000000000000003 \n"
     ]
    }
   ],
   "source": [
    "y_pred_game = np.argmax(model.predict(X_train_game), axis=-1)\n",
    "\n",
    "#Training\n",
    "acc_game = jaccard_score(y_train_game, y_pred_game, average='macro')\n",
    "pre_game = precision_score(y_train_game, y_pred_game, average='macro', zero_division=0)\n",
    "reca_game = recall_score(y_train_game, y_pred_game, average='macro', zero_division=0)\n",
    "f1_game = f1_score(y_train_game, y_pred_game, average='macro', zero_division=0)\n",
    "\n",
    "print(\"___GAME____\")\n",
    "print(f\"accuracy {round(acc_game,3)*100} ,precision {round(pre_game,3)*100}, recall {round(reca_game,3)*100},f1_score {round(f1_game,3)*100} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c558449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Game RESULTS: \n",
      "\n",
      "Avg. Accuracy: 0.014825852019375266\n",
      "Avg. Precision: 0.020654112013889205\n",
      "Avg. Recall: 0.13077782736364632\n",
      "Avg. F1: 0.02818865319568421\n",
      "\n",
      "GAME RESULTS (PER CLASS): \n",
      "\n",
      "Accuracy:\n",
      "walking: 1.0\n",
      "running: 1.0\n",
      "standing: 0.0\n",
      "sitting: 0.0\n",
      "jumping: 6.0\n",
      "\n",
      "Precision:\n",
      "walking: 2.0\n",
      "running: 2.0\n",
      "standing: 0.0\n",
      "sitting: 0.0\n",
      "jumping: 6.0\n",
      "\n",
      "Recall:\n",
      "walking: 1.0\n",
      "running: 1.0\n",
      "standing: 0.0\n",
      "sitting: 0.0\n",
      "jumping: 64.0\n",
      "\n",
      "F1:\n",
      "walking: 1.0\n",
      "running: 1.0\n",
      "standing: 0.0\n",
      "sitting: 0.0\n",
      "jumping: 12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shk/anaconda3/envs/adversarial/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/shk/anaconda3/envs/adversarial/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('\\nGame RESULTS: ')\n",
    "print(\"\\nAvg. Accuracy: {0}\".format(jaccard_score(y_train_game, y_pred_game, average='macro')))\n",
    "print(\"Avg. Precision: {0}\".format(precision_score(y_train_game, y_pred_game, average='macro')))\n",
    "print(\"Avg. Recall: {0}\".format(recall_score(y_train_game, y_pred_game, average='macro')))\n",
    "print(\"Avg. F1: {0}\".format(f1_score(y_train_game, y_pred_game, average='macro')))\n",
    "\n",
    "print(\"\\nGAME RESULTS (PER CLASS): \")\n",
    "print(\"\\nAccuracy:\")\n",
    "for i, rslt in enumerate(jaccard_score(y_train_game, y_pred_game, average=None, labels=cls)):\n",
    "    print(f'{class_names[i]}: {round(rslt,2)*100}')\n",
    "    #print(\"   {0}: {1} %\".format(class_names[i], rslt*100))\n",
    "print(\"\\nPrecision:\")\n",
    "for i, rslt in enumerate(precision_score(y_train_game, y_pred_game, average=None, labels=cls)):\n",
    "    print(f'{class_names[i]}: {round(rslt,2)*100}')\n",
    "    #print(\"   {0}: {1} %\".format(class_names[i], rslt*100))\n",
    "print(\"\\nRecall:\")\n",
    "for i, rslt in enumerate(recall_score(y_train_game, y_pred_game, average=None, labels=cls)):\n",
    "    print(f'{class_names[i]}: {round(rslt,2)*100}')\n",
    "    #print(\"   {0}: {1} %\".format(class_names[i], rslt*100))\n",
    "print(\"\\nF1:\")\n",
    "for i, rslt in enumerate(f1_score(y_train_game, y_pred_game, average=None, labels=cls)):\n",
    "    print(f'{class_names[i]}: {round(rslt,2)*100}')\n",
    "    #print(\"   {0}: {1} %\".format(class_names[i], rslt*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7939d3",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
