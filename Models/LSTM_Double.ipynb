{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b64804f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Basketabll Activity Recognition using Pytorch LSTM Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd2cfe5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a212da3c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, jaccard_score,confusion_matrix, plot_confusion_matrix\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score, confusion_matrix, plot_confusion_matrix\n",
    "files = glob.glob('/data/shk/dl-for-har/tutorial_notebooks/Prof_New/*.csv')\n",
    "\n",
    "name = [file.split('/')[-1] for file in files]\n",
    "df = pd.concat(map(pd.read_csv,files),ignore_index = True) #4230213 rows × 10 columns\n",
    "\n",
    "data = df\n",
    "\n",
    "#Considering only basketball\n",
    "clean_data = data[data['basketball']!='not_labeled']\n",
    "clean_data = clean_data[data['basketball'].notna()]\n",
    "clean_data['basketball'].replace({'jumping':'layup'},inplace=True) #Replacing jumping by layup\n",
    "\n",
    "new_data = clean_data[clean_data.coarse != 'game'] #623758 rows × 10 columns\n",
    "new_data = new_data.drop(columns='coarse')\n",
    "new_data = new_data.iloc[:,:6]\n",
    "print('new_data',new_data.shape)\n",
    "print('____')\n",
    "\n",
    "# Sepearting Game data from train data\n",
    "game_data = clean_data[clean_data.coarse == 'game']\n",
    "game_data = game_data.drop(columns='coarse')\n",
    "game_data = game_data.iloc[:,:6] #45446 rows × 6 columns\n",
    "print('game_data',game_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46d4f84",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Labelling the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afad389",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "label = new_data['basketball']\n",
    "x_axis = sorted(label.unique())\n",
    "y_axis = label.value_counts()\n",
    "\n",
    "X = new_data.iloc[:,:-1]#.astype(np.float32)\n",
    "\n",
    "class_names = ['dribbling','shot','pass','layup','rebound']\n",
    "num_classes = len(class_names)\n",
    "\n",
    "def labelling(clean_data,data_y):\n",
    "    clean_data[data_y == 'dribbling'] = 0\n",
    "    clean_data[data_y == 'shot'] = 1\n",
    "    clean_data[data_y == 'pass'] = 2\n",
    "    clean_data[data_y == 'layup'] = 3\n",
    "    clean_data[data_y == 'rebound'] = 4\n",
    "    \n",
    "    return data_y\n",
    "\n",
    "y = labelling(new_data,new_data.iloc[:,-1]).astype(int)\n",
    "\n",
    "#subject = X['subject']\n",
    "#uni_subject = subject.unique()\n",
    "#uni_subject_count = subject.value_counts()\n",
    "\n",
    "data_labelled = np.concatenate((X, y[:,None]), axis=1)[:,1:] #669204, 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d64384",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Special preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a7047f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_bribbling = data_labelled[data_labelled[:,-1] == 0]\n",
    "data_shot = data_labelled[data_labelled[:,-1] == 1]\n",
    "data_pass = data_labelled[data_labelled[:,-1] == 2]\n",
    "data_layup = data_labelled[data_labelled[:,-1] == 3]\n",
    "data_rebound = data_labelled[data_labelled[:,-1] == 4]\n",
    "\n",
    "\n",
    "def spilt(data):\n",
    "\n",
    "    dd = np.asarray(data)\n",
    "    T = int(0.8* len(dd))\n",
    "    train_size = int(T)\n",
    "    test_size = len(dd) - train_size\n",
    "\n",
    "    train_df,test_df = torch.utils.data.random_split(dd, [train_size,test_size])\n",
    "    X = train_df[:][:,0:4]\n",
    "    Y = train_df[:][:,4]\n",
    "\n",
    "    X_v = test_df[:][:,0:4]\n",
    "    y_v = test_df[:][:,4]\n",
    "  \n",
    "    return X,Y,X_v,y_v\n",
    "\n",
    "X_dribble,Y_dribble,X_v_dribble,y_v_dribble = spilt(data_bribbling)\n",
    "X_shot,Y_shot,X_v_shot,y_v_shot = spilt(data_shot)\n",
    "X_pass,Y_pass,X_v_pass,y_v_pass = spilt(data_pass)\n",
    "X_layup,Y_layup,X_v_layup,y_v_layup = spilt(data_layup)\n",
    "X_rebound,Y_rebound,X_v_rebound,y_v_rebound = spilt(data_rebound)\n",
    "\n",
    "X = np.concatenate((X_dribble, X_shot,X_pass,X_layup,X_rebound), axis=0)[:,1:]\n",
    "Y = np.concatenate((Y_dribble, Y_shot,Y_pass,Y_layup,Y_rebound), axis=0)\n",
    "\n",
    "X_v = np.concatenate((X_v_dribble, X_v_shot,X_v_pass,X_v_layup,X_v_rebound), axis=0)[:,1:]\n",
    "y_v = np.concatenate((y_v_dribble, y_v_shot,y_v_pass,y_v_layup,y_v_rebound), axis=0)\n",
    "\n",
    "train_data = np.column_stack((X,Y))\n",
    "valid_data = np.column_stack((X_v,y_v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b85f455",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Sliding Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485a6af0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def sliding_window(data, samples_per_window, overlap_ratio):\n",
    "    windows = []\n",
    "    indices = []\n",
    "    curr = 0\n",
    "    win_len = int(samples_per_window)\n",
    "    \n",
    "    if overlap_ratio is not None:\n",
    "        overlapping_elements = int((overlap_ratio / 100) * (win_len))\n",
    "        if overlapping_elements >= win_len:\n",
    "            print('Number of overlapping elements exceeds window size.')\n",
    "            return\n",
    "    while curr < len(data) - win_len:\n",
    "        windows.append(data[curr:curr + win_len])\n",
    "        indices.append([curr, curr + win_len])\n",
    "        curr = curr + win_len - overlapping_elements\n",
    "    try:\n",
    "        result_windows = np.array(windows)\n",
    "        result_indices = np.array(indices)\n",
    "    except:\n",
    "        result_windows = np.empty(shape=(len(windows), win_len, data.shape[1]), dtype=object)\n",
    "        result_indices = np.array(indices)\n",
    "        for i in range(0, len(windows)):\n",
    "            result_windows[i] = windows[i]\n",
    "            result_indices[i] = indices[i]\n",
    "    return result_windows, result_indices\n",
    "\n",
    "def apply_sliding_window(data_x, data_y, sliding_window_size, sampling_rate, sliding_window_overlap):\n",
    "    \n",
    "    output_x, _ = sliding_window(data_x, sliding_window_size, sliding_window_overlap)\n",
    "    output_y, _ = sliding_window(data_y, sliding_window_size, sliding_window_overlap)\n",
    "\n",
    "    return output_x,output_y\n",
    "\n",
    "sw_length = 50\n",
    "sw_overlap = 25\n",
    "\n",
    "X_train, y_train = apply_sliding_window(X, Y, sw_length, sampling_rate=50,sliding_window_overlap=sw_overlap)\n",
    "X_valid, y_valid = apply_sliding_window(X_v, y_v, sw_length, sampling_rate=50,sliding_window_overlap=sw_overlap)\n",
    "\n",
    "\n",
    "X_train, y_train = X_train.astype(np.float32), y_train.astype(np.uint8)\n",
    "X_valid, y_valid = X_valid.astype(np.float32), y_valid.astype(np.uint8)\n",
    "\n",
    "print(\"\\nShape of the X_train and Y_train datasets after windowing: \")\n",
    "print(X_train.shape, y_train.shape) \n",
    "\n",
    "print(\"\\nShape of the X_valid and y_valid datasets after windowing: \")\n",
    "print(X_valid.shape, y_valid.shape)\n",
    "\n",
    "y_train = y_train[:, 0]\n",
    "y_valid = y_valid[:, 0]\n",
    "\n",
    "data_X = np.concatenate((X_train,X_valid),axis=0) \n",
    "\n",
    "print(\"\\nShape of the X after windowing: \")\n",
    "print(data_X.shape)\n",
    "\n",
    "print(\"\\nShape of the Y after windowing: \")\n",
    "data_Y = np.concatenate((y_train,y_valid),axis=0) \n",
    "print(data_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b5af62",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8a214a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim , hidden_size , num_layers):\n",
    "        super(Network, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size= input_dim , hidden_size = hidden_size , num_layers= num_layers ,\n",
    "                            batch_first=True, dropout = 0.1,bidirectional = True)\n",
    "\n",
    "        self.lstm1 = nn.LSTM(input_size=hidden_size*2, hidden_size=hidden_size, num_layers=num_layers,\n",
    "                            batch_first=True, dropout=0.1, bidirectional=True)\n",
    "        self.dropout1 = nn.Dropout(p=0.1)       \n",
    "        self.linear1 = nn.Linear(2*1300,250)\n",
    "        self.linear2 = nn.Linear(250,500)\n",
    "        self.linear3 = nn.Linear(500,130)\n",
    "        self.dropout2 = nn.Dropout(p=0.2)\n",
    "        self.dropout3 = nn.Dropout(p=0.3)\n",
    "        self.linear5 = nn.Linear(130,5)\n",
    "\n",
    "    def forward(self, x):  \n",
    "        x,_ = self.lstm(x)\n",
    "        x, _ = self.lstm1(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.reshape(-1,x.shape[1]*x.shape[2])     \n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.relu(self.linear2(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = self.relu(self.linear3(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = self.linear5(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "inp_dim = 3\n",
    "hd = 26\n",
    "nl = 3\n",
    "\n",
    "torch_model = Network(inp_dim,hd,nl)\n",
    "torch_model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a144fb4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22237566",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(torch_model.parameters(), lr=1e-5, weight_decay=1e-4)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train))       \n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=12)\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(torch.from_numpy(X_valid).float(), torch.from_numpy(y_valid))\n",
    "valloader = torch.utils.data.DataLoader(test_dataset, shuffle=True, batch_size=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb35d6f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df496da",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs = 250\n",
    "check=0\n",
    "for e in range(num_epochs):\n",
    "    \n",
    "    best_accuracy=0.0\n",
    "    train_accuracy=0.0\n",
    "    train_loss=0.0\n",
    "\n",
    "    train_losses = []\n",
    "    train_preds = []\n",
    "    train_gt = []\n",
    "    start_time = time.time()\n",
    "    batch_num = 1\n",
    "    k=0 \n",
    "    \n",
    "    for x, y in trainloader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        train_output = torch_model(x)\n",
    "        loss = criterion(train_output, y.long())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        y_preds = np.argmax(train_output.cpu().detach().numpy(), axis=-1)\n",
    "\n",
    "        y_true = y.cpu().numpy()\n",
    "\n",
    "        train_preds = np.concatenate((np.array(train_preds, int), np.array(y_preds, int)))\n",
    "        train_gt = np.concatenate((np.array(train_gt, int), np.array(y_true, int)))\n",
    "\n",
    "        if batch_num % 6000 == 0 and batch_num > 0:\n",
    "            cur_loss = np.mean(train_losses)\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d} batches | ms/batch {:5.2f} | train loss {:5.2f}'.format(e, batch_num,\n",
    "                                                                                                         elapsed * 1000 / 16, cur_loss))\n",
    "            start_time = time.time()\n",
    "\n",
    "        batch_num += 1\n",
    "\n",
    "\n",
    "    acc = jaccard_score(train_gt, train_preds, average='macro')\n",
    "    pre = precision_score(train_gt, train_preds, average='macro', zero_division=0)\n",
    "    reca = recall_score(train_gt, train_preds, average='macro', zero_division=0)\n",
    "    f1 = f1_score(train_gt, train_preds, average='macro', zero_division=0)\n",
    "\n",
    "    print(\"___Training____\")\n",
    "    print(f\"Epoch {e},accuracy {round(acc,3)*100} ,precision {round(pre,3)*100}, recall {round(reca,3)*100}, f1_score {round(f1,3)*100} \")\n",
    "\n",
    "    val_preds = []\n",
    "    val_gt = []\n",
    "    val_losses = []\n",
    "\n",
    "    # sets network to eval mode and\n",
    "    torch_model.eval()\n",
    "    test_accuracy=0.0\n",
    "    with torch.no_grad():\n",
    "        for x, y in valloader:\n",
    "            # send inputs through network to get predictions\n",
    "            val_output = torch_model(x)\n",
    "\n",
    "            val_loss = criterion(val_output, y.long())\n",
    "\n",
    "            val_losses.append(val_loss.item())\n",
    "\n",
    "            y_preds = np.argmax(val_output.cpu().numpy(), axis=-1)\n",
    "            y_true = y.cpu().numpy()\n",
    "\n",
    "            val_preds = np.concatenate((np.array(val_preds, int), np.array(y_preds, int)))\n",
    "            val_gt = np.concatenate((np.array(val_gt, int), np.array(y_true, int)))\n",
    "\n",
    "        acc_test = jaccard_score(val_gt, val_preds, average='macro')\n",
    "        pre_test = precision_score(val_gt, val_preds, average='macro', zero_division=0)\n",
    "        reca_test = recall_score(val_gt, val_preds, average='macro', zero_division=0)\n",
    "        f1_test = f1_score(val_gt, val_preds, average='macro', zero_division=0)\n",
    "\n",
    "        print(\"___Testing____\")\n",
    "        print(f\"accuracy {round(acc_test,3)*100} ,precision {round(pre_test,3)*100}, recall {round(reca_test,3)*100}, f1_score {round(f1_test,3)*100} \")\n",
    "\n",
    "    torch.save(torch_model.state_dict(), os.path.join( './Pre_Trained_models/epoch-{}.pt'.format(e)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec23057",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dcdeb9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cls = np.array(range(5))\n",
    "class_names = ['dribbling','shot','pass','layup','rebound']\n",
    "\n",
    "print('\\nTraining RESULTS: ')\n",
    "print(\"\\nAvg. Accuracy: {0}\".format(jaccard_score(train_gt, train_preds, average='macro')))\n",
    "print(\"Avg. Precision: {0}\".format(precision_score(train_gt, train_preds, average='macro')))\n",
    "print(\"Avg. Recall: {0}\".format(recall_score(train_gt, train_preds, average='macro')))\n",
    "print(\"Avg. F1: {0}\".format(f1_score(train_gt, train_preds, average='macro')))\n",
    "\n",
    "print(\"\\nTraining RESULTS (PER CLASS): \")\n",
    "print(\"\\nAccuracy:\")\n",
    "for i, rslt in enumerate(jaccard_score(train_gt, train_preds, average=None, labels=cls)):\n",
    "    print(\"   {0}: {1} %\".format(class_names[i], rslt*100))\n",
    "print(\"\\nPrecision:\")\n",
    "for i, rslt in enumerate(precision_score(train_gt, train_preds, average=None, labels=cls)):\n",
    "    print(\"   {0}: {1} %\".format(class_names[i], rslt*100))\n",
    "print(\"\\nRecall:\")\n",
    "for i, rslt in enumerate(recall_score(train_gt, train_preds, average=None, labels=cls)):\n",
    "    print(\"   {0}: {1} %\".format(class_names[i], rslt*100))\n",
    "print(\"\\nF1:\")\n",
    "for i, rslt in enumerate(f1_score(train_gt, train_preds, average=None, labels=cls)):\n",
    "    print(\"   {0}: {1} %\".format(class_names[i], rslt*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2ce0b5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Validation Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b632d0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('\\nValidation RESULTS: ')\n",
    "print(\"\\nAvg. Accuracy: {0}\".format(jaccard_score(test_gt, test_preds, average='macro')))\n",
    "print(\"Avg. Precision: {0}\".format(precision_score(test_gt, test_preds, average='macro')))\n",
    "print(\"Avg. Recall: {0}\".format(recall_score(test_gt, test_preds, average='macro')))\n",
    "print(\"Avg. F1: {0}\".format(f1_score(test_gt, test_preds, average='macro')))\n",
    "\n",
    "print(\"\\nVALIDATION RESULTS (PER CLASS): \")\n",
    "print(\"\\nAccuracy:\")\n",
    "for i, rslt in enumerate(jaccard_score(test_gt, test_preds, average=None, labels=cls)):\n",
    "    print(f'{class_names[i]}: {round(rslt,2)*100}')\n",
    "\n",
    "print(\"\\nPrecision:\")\n",
    "for i, rslt in enumerate(precision_score(test_gt, test_preds, average=None, labels=cls)):\n",
    "    print(f'{class_names[i]}: {round(rslt,2)*100}')\n",
    "\n",
    "print(\"\\nRecall:\")\n",
    "for i, rslt in enumerate(recall_score(test_gt, test_preds, average=None, labels=cls)):\n",
    "    print(f'{class_names[i]}: {round(rslt,2)*100}')\n",
    "\n",
    "print(\"\\nF1:\")\n",
    "for i, rslt in enumerate(f1_score(test_gt, test_preds, average=None, labels=cls)):\n",
    "    print(f'{class_names[i]}: {round(rslt,2)*100}')\n",
    "\n",
    "    \n",
    "print(\"\\nGENERALIZATION GAP ANALYSIS: \")\n",
    "print(\"\\nTrain-Val-Accuracy Difference: {0}\".format(jaccard_score(train_gt, train_preds, average='macro') -\n",
    "                                                  jaccard_score(test_gt, test_preds, average='macro')))\n",
    "print(\"Train-Val-Precision Difference: {0}\".format(precision_score(train_gt, train_preds, average='macro') -\n",
    "                                                   precision_score(test_gt, test_preds, average='macro')))\n",
    "print(\"Train-Val-Recall Difference: {0}\".format(recall_score(train_gt, train_preds, average='macro') -\n",
    "                                                recall_score(test_gt, test_preds, average='macro')))\n",
    "print(\"Train-Val-F1 Difference: {0}\".format(f1_score(train_gt, train_preds, average='macro') -\n",
    "                                            f1_score(test_gt, test_preds, average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4973d204",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Testing on Game data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29c765e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('game_data',game_data.shape)\n",
    "\n",
    "label_game = game_data['basketball']\n",
    "x_axis_game = sorted(label_game.unique())\n",
    "y_axis_game = label_game.value_counts()\n",
    "\n",
    "X_game = game_data.iloc[:,:-1]\n",
    "\n",
    "def labelling(clean_data,data_y):\n",
    "    clean_data[data_y == 'dribbling'] = 0\n",
    "    clean_data[data_y == 'shot'] = 1\n",
    "    clean_data[data_y == 'pass'] = 2\n",
    "    clean_data[data_y == 'layup'] = 3\n",
    "    clean_data[data_y == 'rebound'] = 4\n",
    "    \n",
    "    return data_y\n",
    "\n",
    "y_game = labelling(game_data,game_data.iloc[:,-1]).astype(int)\n",
    "\n",
    "data_labelled_game = np.concatenate((X_game, y_game[:,None]), axis=1)[:,2:] #669204, 6\n",
    "print('data_labelled_game ',data_labelled_game.shape)\n",
    "\n",
    "data_labelled_X = data_labelled_game[:,:-1]\n",
    "data_labelled_Y = data_labelled_game[:,-1]\n",
    "\n",
    "print(data_labelled_X.shape,data_labelled_Y.shape)\n",
    "sw_length = 50\n",
    "sw_overlap = 25\n",
    "\n",
    "X_train_game, y_train_game = apply_sliding_window(data_labelled_X, data_labelled_Y, sliding_window_size=sw_length, \n",
    "                                        sampling_rate=50,sliding_window_overlap=sw_overlap)\n",
    "\n",
    "\n",
    "X_train_game, y_train_game = X_train_game.astype(np.float32), y_train_game[:,0].astype(np.uint8)\n",
    "\n",
    "print(\"\\nShape of the X_train_game and y_train_game datasets after windowing: \")\n",
    "print(X_train_game.shape, y_train_game.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50ad833",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load the pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64abe824",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load('./Pre_Trained_models/epoch-249.pt')\n",
    "#model = ConvNet(num_classes=8)\n",
    "torch_model.load_state_dict(checkpoint)\n",
    "torch_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd02095",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Testing on game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a959308f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('game_data',game_data.shape)\n",
    "\n",
    "label_game = game_data['basketball']\n",
    "x_axis_game = sorted(label_game.unique())\n",
    "y_axis_game = label_game.value_counts()\n",
    "\n",
    "X_game = game_data.iloc[:,:-1]\n",
    "\n",
    "def labelling(clean_data,data_y):\n",
    "    clean_data[data_y == 'dribbling'] = 0\n",
    "    clean_data[data_y == 'shot'] = 1\n",
    "    clean_data[data_y == 'pass'] = 2\n",
    "    clean_data[data_y == 'layup'] = 3\n",
    "    clean_data[data_y == 'rebound'] = 4\n",
    "    \n",
    "    return data_y\n",
    "\n",
    "y_game = labelling(game_data,game_data.iloc[:,-1]).astype(int)\n",
    "\n",
    "data_labelled_game = np.concatenate((X_game, y_game[:,None]), axis=1)[:,2:] #669204, 6\n",
    "print('data_labelled_game ',data_labelled_game.shape)\n",
    "\n",
    "data_labelled_X = data_labelled_game[:,:-1]\n",
    "data_labelled_Y = data_labelled_game[:,-1]\n",
    "\n",
    "print(data_labelled_X.shape,data_labelled_Y.shape)\n",
    "sw_length = 50\n",
    "sw_overlap = 25\n",
    "\n",
    "X_train_game, y_train_game = apply_sliding_window(data_labelled_X, data_labelled_Y, sliding_window_size=sw_length, \n",
    "                                        sampling_rate=50,sliding_window_overlap=sw_overlap)\n",
    "\n",
    "\n",
    "X_train_game, y_train_game = X_train_game.astype(np.float32), y_train_game[:,0].astype(np.uint8)\n",
    "\n",
    "print(\"\\nShape of the X_train_game and y_train_game datasets after windowing: \")\n",
    "print(X_train_game.shape, y_train_game.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48055d35",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train_game, y_train_game_ = torch.from_numpy(X_train_game).float(), torch.from_numpy(y_train_game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3c1f29",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "output_game = torch_model(X_train_game)\n",
    "loss = criterion(output_game, y_train_game_.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f5fdaa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "g_train_preds =[]\n",
    "g_train_gt = []\n",
    "y_pred_game = np.argmax(output_game.cpu().detach().numpy(), axis=-1)\n",
    "\n",
    "y_game = y_train_game_.cpu().numpy()\n",
    "\n",
    "train_preds = np.concatenate((np.array(g_train_preds, int), np.array(y_pred_game, int)))\n",
    "train_gt = np.concatenate((np.array(g_train_gt, int), np.array(y_game, int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10070a2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "acc_game = jaccard_score(y_game, y_pred_game, average='macro')\n",
    "pre_game = precision_score(y_game, y_pred_game, average='macro', zero_division=0)\n",
    "reca_game = recall_score(y_game, y_pred_game, average='macro', zero_division=0)\n",
    "f1_game = f1_score(y_game, y_pred_game, average='macro', zero_division=0)\n",
    "\n",
    "cls = np.array(range(5))\n",
    "class_names = ['dribbling','shot','pass','layup','rebound']\n",
    "\n",
    "print(\"___GAME____\")\n",
    "print('Game_loss',loss)\n",
    "print(f\"accuracy {round(acc_game,3)*100} ,precision {round(pre_game,3)*100}, recall {round(reca_game,3)*100},f1_score {round(f1_game,3)*100} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b82b2a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('\\nGame RESULTS: ')\n",
    "print(\"\\nAvg. Accuracy: {0}\".format(jaccard_score(y_game, y_pred_game, average='macro')))\n",
    "print(\"Avg. Precision: {0}\".format(precision_score(y_game, y_pred_game, average='macro')))\n",
    "print(\"Avg. Recall: {0}\".format(recall_score(y_game, y_pred_game, average='macro')))\n",
    "print(\"Avg. F1: {0}\".format(f1_score(y_game, y_pred_game, average='macro')))\n",
    "\n",
    "print(\"\\nGAME RESULTS (PER CLASS): \")\n",
    "print(\"\\nAccuracy:\")\n",
    "for i, rslt in enumerate(jaccard_score(y_game, y_pred_game, average=None, labels=cls)):\n",
    "    print(f'{class_names[i]}: {round(rslt,2)*100}')\n",
    "    #print(\"   {0}: {1} %\".format(class_names[i], rslt*100))\n",
    "print(\"\\nPrecision:\")\n",
    "for i, rslt in enumerate(precision_score(y_game, y_pred_game, average=None, labels=cls)):\n",
    "    print(f'{class_names[i]}: {round(rslt,2)*100}')\n",
    "    #print(\"   {0}: {1} %\".format(class_names[i], rslt*100))\n",
    "print(\"\\nRecall:\")\n",
    "for i, rslt in enumerate(recall_score(y_game, y_pred_game, average=None, labels=cls)):\n",
    "    print(f'{class_names[i]}: {round(rslt,2)*100}')\n",
    "    #print(\"   {0}: {1} %\".format(class_names[i], rslt*100))\n",
    "print(\"\\nF1:\")\n",
    "for i, rslt in enumerate(f1_score(y_game, y_pred_game, average=None, labels=cls)):\n",
    "    print(f'{class_names[i]}: {round(rslt,2)*100}')\n",
    "    #print(\"   {0}: {1} %\".format(class_names[i], rslt*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
